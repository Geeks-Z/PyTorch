{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/team/zhaohongwei/anaconda3/envs/torch_hwzhao/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 输入图像channel：1；输出channel：6；5x5卷积核\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 2x2 Max pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # 如果是方阵,则可以只使用一个数字进行定义\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # 除去批处理维度的其他所有维度\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0921,  0.0474,  0.0372, -0.0836, -0.1015, -0.0173,  0.0596,  0.0553,\n",
      "         -0.1055,  0.1675]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([2, 2])\n",
      "bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # 使用nn.Parameter定义权重和偏置\n",
    "        self.weight = nn.Parameter(torch.randn(2, 2))\n",
    "        self.bias = nn.Parameter(torch.zeros(2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 在前向传播中使用定义的参数\n",
    "        x = torch.matmul(x, self.weight) + self.bias\n",
    "        return x\n",
    "\n",
    "# 实例化模型\n",
    "model = MyModel()\n",
    "\n",
    "# 打印模型参数\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([10, 1, 5, 5])\n",
      "conv1.bias torch.Size([10])\n",
      "conv2.weight torch.Size([20, 10, 5, 5])\n",
      "conv2.bias torch.Size([20])\n",
      "fc1.weight torch.Size([50, 320])\n",
      "fc1.bias torch.Size([50])\n",
      "fc2.weight torch.Size([10, 50])\n",
      "fc2.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 定义一个简单的模型\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播逻辑\n",
    "        pass\n",
    "\n",
    "# 实例化模型\n",
    "model = SimpleModel()\n",
    "\n",
    "# 使用 named_parameters() 遍历模型参数\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 5, 5])\n",
      "torch.Size([10])\n",
      "torch.Size([20, 10, 5, 5])\n",
      "torch.Size([20])\n",
      "torch.Size([50, 320])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 权值初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "conv = nn.Conv2d(1,3,3)\n",
    "linear = nn.Linear(10,1)\n",
    "\n",
    "print(isinstance(conv,nn.Conv2d)) # 判断conv是否是nn.Conv2d类型\n",
    "print(isinstance(linear,nn.Conv2d)) # 判断linear是否是nn.Conv2d类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0866,  0.2790, -0.0341, -0.2344,  0.0400, -0.1183, -0.2698, -0.0791,\n",
       "         -0.2824, -0.1778]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.data\n",
    "linear.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
       "         0.3000]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对conv进行kaiming初始化\n",
    "torch.nn.init.kaiming_normal_(conv.weight.data)\n",
    "conv.weight.data\n",
    "# 对linear进行常数初始化\n",
    "torch.nn.init.constant_(linear.weight.data,0.3)\n",
    "linear.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型加载与保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练前:  tensor([[[ 0.0663,  0.1155,  0.0588, -0.0793, -0.0634],\n",
      "         [-0.0235,  0.1004,  0.0122, -0.0956,  0.0776],\n",
      "         [ 0.0357, -0.1122,  0.0310,  0.0453, -0.0823],\n",
      "         [-0.1140, -0.0801, -0.1007, -0.0095, -0.0445],\n",
      "         [-0.0524, -0.0345,  0.0624,  0.0884, -0.0357]],\n",
      "\n",
      "        [[-0.0626,  0.0563,  0.0243, -0.1103,  0.0023],\n",
      "         [ 0.0951, -0.0181, -0.1153, -0.0853,  0.0355],\n",
      "         [ 0.0713, -0.0709, -0.0379,  0.0242,  0.0476],\n",
      "         [-0.0903,  0.0322,  0.0994,  0.0152, -0.0590],\n",
      "         [ 0.0324,  0.0886,  0.0415,  0.0373, -0.0832]],\n",
      "\n",
      "        [[-0.0949,  0.0828, -0.0199, -0.0991, -0.0592],\n",
      "         [ 0.0776, -0.0896,  0.0081, -0.0105, -0.0269],\n",
      "         [ 0.1046, -0.0198, -0.0831,  0.0023,  0.0971],\n",
      "         [-0.0556, -0.0557, -0.1149,  0.0150,  0.0603],\n",
      "         [-0.0686,  0.0720, -0.0763, -0.0072,  0.1149]]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "训练后:  tensor([[[2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.]],\n",
      "\n",
      "        [[2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.]],\n",
      "\n",
      "        [[2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.]]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class LeNet2(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(LeNet2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def initialize(self):\n",
    "        for p in self.parameters():\n",
    "            p.data.fill_(2020)\n",
    "\n",
    "net = LeNet2(classes=2019)\n",
    "\n",
    "# \"训练\"\n",
    "print(\"训练前: \", net.features[0].weight[0, ...])\n",
    "net.initialize()\n",
    "print(\"训练后: \", net.features[0].weight[0, ...])\n",
    "\n",
    "path_model = \"./model.pkl\"\n",
    "path_state_dict = \"./model_state_dict.pkl\"\n",
    "\n",
    "# 保存整个模型\n",
    "torch.save(net, path_model)\n",
    "\n",
    "# 保存模型参数\n",
    "net_state_dict = net.state_dict()\n",
    "torch.save(net_state_dict, path_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=84, out_features=2019, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "path_model = \"./model.pkl\"\n",
    "net_load = torch.load(path_model)\n",
    "\n",
    "print(net_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载前:  tensor([[[ 0.0775,  0.0374,  0.0163,  0.0196, -0.0884],\n",
      "         [ 0.0293, -0.1051, -0.0362,  0.1122, -0.0616],\n",
      "         [ 0.0083,  0.0274,  0.0158,  0.0301,  0.0937],\n",
      "         [-0.0459, -0.1062,  0.0510, -0.0058,  0.1046],\n",
      "         [-0.0672, -0.0204,  0.0134,  0.0594,  0.0421]],\n",
      "\n",
      "        [[ 0.0058, -0.0435, -0.0550,  0.0591, -0.1067],\n",
      "         [ 0.0929,  0.0202, -0.0027,  0.0264,  0.0409],\n",
      "         [ 0.0038, -0.0219, -0.0522, -0.0065,  0.0717],\n",
      "         [-0.0300, -0.0819, -0.0238, -0.0132, -0.0364],\n",
      "         [ 0.0258, -0.0238, -0.0680, -0.0172,  0.0902]],\n",
      "\n",
      "        [[-0.1087,  0.0948, -0.0848,  0.1148, -0.0212],\n",
      "         [-0.0634,  0.0479,  0.0064, -0.0287,  0.0732],\n",
      "         [-0.1080,  0.0522, -0.0891, -0.1137,  0.0838],\n",
      "         [ 0.0740,  0.0965,  0.0893, -0.1075,  0.0277],\n",
      "         [-0.0060, -0.0713,  0.0996,  0.0865, -0.0181]]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "加载后:  tensor([[[2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.]],\n",
      "\n",
      "        [[2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.]],\n",
      "\n",
      "        [[2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.],\n",
      "         [2020., 2020., 2020., 2020., 2020.]]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "path_state_dict = \"./model_state_dict.pkl\"\n",
    "state_dict_load = torch.load(path_state_dict)\n",
    "net_new = LeNet2(classes=2019)\n",
    "\n",
    "print(\"加载前: \", net_new.features[0].weight[0, ...])\n",
    "net_new.load_state_dict(state_dict_load)\n",
    "print(\"加载后: \", net_new.features[0].weight[0, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model.state_dict:\n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([120, 400])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([84, 120])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n",
      "Optimizer`s state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    " \n",
    "#define model\n",
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass,self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,6,5)\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,10)\n",
    " \n",
    "    def forward(self,x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=x.view(-1,16*5*5)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    " \n",
    "def main():\n",
    "    # Initialize model\n",
    "    model = TheModelClass()\n",
    " \n",
    "    #Initialize optimizer\n",
    "    optimizer=optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\n",
    " \n",
    "    #print model's state_dict\n",
    "    print('Model.state_dict:')\n",
    "    for param_tensor in model.state_dict():\n",
    "        #打印 key value字典\n",
    "        print(param_tensor,'\\t',model.state_dict()[param_tensor].size())\n",
    " \n",
    "    #print optimizer's state_dict\n",
    "    print('Optimizer`s state_dict:')\n",
    "    for var_name in optimizer.state_dict():\n",
    "        print(var_name,'\\t',optimizer.state_dict()[var_name])\n",
    " \n",
    " \n",
    " \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# 设置权重，服从正态分布  --> 2 x 2\n",
    "weight = torch.randn((2, 2), requires_grad=True)\n",
    "# 设置梯度为全1矩阵  --> 2 x 2\n",
    "weight.grad = torch.ones((2, 2))\n",
    "# 输出现有的weight和data\n",
    "print(\"The data of weight before step:\\n{}\".format(weight.data))\n",
    "print(\"The grad of weight before step:\\n{}\".format(weight.grad))\n",
    "# 实例化优化器\n",
    "optimizer = torch.optim.SGD([weight], lr=0.1, momentum=0.9)\n",
    "# 进行一步操作\n",
    "optimizer.step()\n",
    "# 查看进行一步后的值，梯度\n",
    "print(\"The data of weight after step:\\n{}\".format(weight.data))\n",
    "print(\"The grad of weight after step:\\n{}\".format(weight.grad))\n",
    "# 权重清零\n",
    "optimizer.zero_grad()\n",
    "# 检验权重是否为0\n",
    "print(\"The grad of weight after optimizer.zero_grad():\\n{}\".format(weight.grad))\n",
    "# 输出参数\n",
    "print(\"optimizer.params_group is \\n{}\".format(optimizer.param_groups))\n",
    "# 查看参数位置，optimizer和weight的位置一样，我觉得这里可以参考Python是基于值管理\n",
    "print(\"weight in optimizer:{}\\nweight in weight:{}\\n\".format(id(optimizer.param_groups[0]['params'][0]), id(weight)))\n",
    "# 添加参数：weight2\n",
    "weight2 = torch.randn((3, 3), requires_grad=True)\n",
    "optimizer.add_param_group({\"params\": weight2, 'lr': 0.0001, 'nesterov': True})\n",
    "# 查看现有的参数\n",
    "print(\"optimizer.param_groups is\\n{}\".format(optimizer.param_groups))\n",
    "# 查看当前状态信息\n",
    "opt_state_dict = optimizer.state_dict()\n",
    "print(\"state_dict before step:\\n\", opt_state_dict)\n",
    "# 进行5次step操作\n",
    "for _ in range(50):\n",
    "    optimizer.step()\n",
    "# 输出现有状态信息\n",
    "print(\"state_dict after step:\\n\", optimizer.state_dict())\n",
    "# 保存参数信息\n",
    "torch.save(optimizer.state_dict(),os.path.join(r\"D:\\pythonProject\\Attention_Unet\", \"optimizer_state_dict.pkl\"))\n",
    "print(\"----------done-----------\")\n",
    "# 加载参数信息\n",
    "state_dict = torch.load(r\"D:\\pythonProject\\Attention_Unet\\optimizer_state_dict.pkl\") # 需要修改为你自己的路径\n",
    "optimizer.load_state_dict(state_dict)\n",
    "print(\"load state_dict successfully\\n{}\".format(state_dict))\n",
    "# 输出最后属性信息\n",
    "print(\"\\n{}\".format(optimizer.defaults))\n",
    "print(\"\\n{}\".format(optimizer.state))\n",
    "print(\"\\n{}\".format(optimizer.param_groups))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型容器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetSequetial(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(LeNet2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, 2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (linears): ModuleList(\n",
      "    (0-19): 20 x Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[-0.1253, -0.1615, -0.3969, -0.2678,  0.2628, -0.0124, -0.0215, -0.0008,\n",
      "         -0.1870,  0.1515],\n",
      "        [-0.1253, -0.1615, -0.3969, -0.2678,  0.2628, -0.0124, -0.0215, -0.0008,\n",
      "         -0.1870,  0.1515],\n",
      "        [-0.1253, -0.1615, -0.3969, -0.2678,  0.2628, -0.0124, -0.0215, -0.0008,\n",
      "         -0.1870,  0.1515],\n",
      "        [-0.1253, -0.1615, -0.3969, -0.2678,  0.2628, -0.0124, -0.0215, -0.0008,\n",
      "         -0.1870,  0.1515],\n",
      "        [-0.1253, -0.1615, -0.3969, -0.2678,  0.2628, -0.0124, -0.0215, -0.0008,\n",
      "         -0.1870,  0.1515],\n",
      "        [-0.1253, -0.1615, -0.3969, -0.2678,  0.2628, -0.0124, -0.0215, -0.0008,\n",
      "         -0.1870,  0.1515],\n",
      "        [-0.1253, -0.1615, -0.3969, -0.2678,  0.2628, -0.0124, -0.0215, -0.0008,\n",
      "         -0.1870,  0.1515],\n",
      "        [-0.1253, -0.1615, -0.3969, -0.2678,  0.2628, -0.0124, -0.0215, -0.0008,\n",
      "         -0.1870,  0.1515],\n",
      "        [-0.1253, -0.1615, -0.3969, -0.2678,  0.2628, -0.0124, -0.0215, -0.0008,\n",
      "         -0.1870,  0.1515],\n",
      "        [-0.1253, -0.1615, -0.3969, -0.2678,  0.2628, -0.0124, -0.0215, -0.0008,\n",
      "         -0.1870,  0.1515]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class ModuleList(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModuleList, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(20)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, linear in enumerate(self.linears):\n",
    "            x = linear(x)\n",
    "        return x\n",
    "\n",
    "net = ModuleList()\n",
    "\n",
    "print(net)\n",
    "\n",
    "fake_data = torch.ones((10, 10))\n",
    "\n",
    "output = net(fake_data)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.4056, 0.1909, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.9579, 0.4126],\n",
      "          [0.0000, 0.6611, 0.0000,  ..., 0.0000, 0.3082, 0.3409],\n",
      "          ...,\n",
      "          [0.0000, 0.3477, 0.0000,  ..., 0.1169, 0.0000, 0.1187],\n",
      "          [0.0000, 0.0000, 0.1221,  ..., 0.0000, 0.0000, 0.1232],\n",
      "          [0.0000, 0.1271, 0.0539,  ..., 0.0000, 0.0000, 0.0387]],\n",
      "\n",
      "         [[0.0000, 1.1290, 0.0000,  ..., 0.0983, 0.0000, 0.4820],\n",
      "          [1.2758, 0.0000, 0.0000,  ..., 0.0637, 0.3755, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0236, 0.9434, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.2883, 0.0000,  ..., 0.6844, 0.6549, 0.0085],\n",
      "          [0.0000, 0.2142, 0.7710,  ..., 0.2872, 0.5901, 0.1529],\n",
      "          [0.6774, 0.0000, 0.6228,  ..., 0.4654, 0.0000, 0.7522]],\n",
      "\n",
      "         [[0.0066, 0.5943, 0.1602,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.3983, 0.0000, 0.1716,  ..., 0.2854, 0.8466, 1.0427],\n",
      "          [0.0000, 0.2751, 0.0000,  ..., 0.2906, 0.3807, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2106, 0.0000],\n",
      "          [0.0000, 0.0000, 0.2420,  ..., 0.1524, 0.0106, 0.0000],\n",
      "          [0.6415, 0.0000, 0.0000,  ..., 0.2389, 0.5732, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1676, 0.2590, 0.0689,  ..., 0.5262, 1.5134, 0.0000],\n",
      "          [0.0000, 0.5581, 0.0000,  ..., 0.2192, 0.0000, 0.0000],\n",
      "          [0.0116, 0.9918, 0.0000,  ..., 0.1061, 0.0000, 0.0840],\n",
      "          ...,\n",
      "          [0.0000, 0.2705, 0.0310,  ..., 0.0000, 0.5824, 0.0000],\n",
      "          [0.0000, 1.1943, 0.2025,  ..., 0.8522, 1.4341, 0.0000],\n",
      "          [0.0000, 0.0000, 0.8231,  ..., 0.1877, 0.0000, 0.0971]],\n",
      "\n",
      "         [[0.0000, 0.4759, 0.0000,  ..., 0.3328, 0.4141, 0.5377],\n",
      "          [0.0000, 1.6866, 0.0000,  ..., 0.0000, 0.6113, 0.0000],\n",
      "          [0.0000, 0.6076, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1464, 0.9910, 0.0000,  ..., 0.7905, 0.1907, 0.0000],\n",
      "          [0.0000, 0.0000, 0.7109,  ..., 0.0000, 0.5656, 0.0000],\n",
      "          [0.0000, 0.5244, 0.0000,  ..., 0.0000, 0.0861, 0.1314]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.4067,  ..., 0.0000, 0.0000, 0.1036],\n",
      "          [0.8047, 0.0000, 0.0000,  ..., 0.1092, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1087, 0.4356],\n",
      "          ...,\n",
      "          [0.1711, 0.0000, 0.0000,  ..., 0.4288, 0.1686, 0.7484],\n",
      "          [0.0000, 0.0000, 0.3742,  ..., 0.0623, 0.0000, 1.1138],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7277, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.1134, 0.9558, 0.0000,  ..., 0.1537, 0.0508, 0.5732],\n",
      "          [1.2472, 0.0000, 0.3626,  ..., 0.0000, 0.0000, 0.0888],\n",
      "          [0.1856, 0.2331, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3479, 0.0000, 0.0000],\n",
      "          [1.2288, 0.0000, 0.0000,  ..., 0.0000, 0.3936, 0.1029],\n",
      "          [0.0000, 0.5020, 0.1062,  ..., 0.3310, 0.0443, 0.0000]],\n",
      "\n",
      "         [[0.1053, 0.0000, 0.2898,  ..., 0.0000, 0.2809, 0.8351],\n",
      "          [0.0000, 0.8324, 0.0000,  ..., 0.5502, 0.0660, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0874,  ..., 0.0000, 0.4569, 0.0000],\n",
      "          ...,\n",
      "          [1.0403, 0.0000, 0.2898,  ..., 0.1608, 0.2811, 0.0000],\n",
      "          [0.5080, 0.0000, 0.7509,  ..., 0.2296, 0.0000, 0.0000],\n",
      "          [0.7556, 0.0000, 0.0813,  ..., 0.4025, 0.0000, 0.1665]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0666],\n",
      "          [1.4503, 0.0669, 0.7807,  ..., 0.0783, 0.0000, 0.0000],\n",
      "          [0.6118, 0.2631, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0889, 0.9793],\n",
      "          [0.0000, 0.0000, 0.6187,  ..., 0.9513, 0.4451, 0.0000],\n",
      "          [0.5710, 0.2103, 0.3355,  ..., 0.0000, 0.4234, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.0000, 0.1620,  ..., 0.0000, 0.0475, 0.2021],\n",
      "          [0.0000, 0.2248, 0.0959,  ..., 0.0000, 0.0846, 0.1228],\n",
      "          [0.7523, 0.6316, 0.0000,  ..., 0.3838, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 1.0404, 0.3427,  ..., 0.2050, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3094, 1.1213, 0.1421],\n",
      "          [0.0000, 0.3921, 0.4036,  ..., 0.1327, 0.1496, 0.0000]],\n",
      "\n",
      "         [[0.9972, 0.4157, 0.0000,  ..., 0.4907, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.2965,  ..., 0.0000, 0.2060, 0.6229],\n",
      "          [0.1113, 0.0000, 0.7038,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 1.0867, 0.2847,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0430, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.8745, 0.0000, 0.0000,  ..., 0.5403, 0.2965, 0.1485]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.5453],\n",
      "          [0.9807, 0.4635, 0.0000,  ..., 0.8582, 0.2848, 0.3135],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.6684, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0077, 0.0000,  ..., 0.8919, 0.0898, 0.2002],\n",
      "          [0.0520, 0.0000, 0.0020,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2672, 0.6038, 0.0000,  ..., 1.2288, 0.5905, 0.5330]]],\n",
      "\n",
      "\n",
      "        [[[0.1673, 0.6062, 0.4868,  ..., 0.6580, 0.2945, 0.9210],\n",
      "          [0.0000, 0.2192, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.9666, 0.0000],\n",
      "          ...,\n",
      "          [0.3469, 0.7136, 0.9326,  ..., 0.7070, 1.3690, 0.0000],\n",
      "          [0.0000, 0.1611, 0.0000,  ..., 0.1436, 0.5458, 0.8666],\n",
      "          [0.0000, 0.1215, 0.8914,  ..., 0.6591, 0.0000, 0.2975]],\n",
      "\n",
      "         [[0.1418, 0.0000, 0.0000,  ..., 0.0000, 0.6269, 0.3185],\n",
      "          [0.0000, 1.0100, 0.1548,  ..., 0.4658, 0.0000, 0.0000],\n",
      "          [0.0000, 1.1714, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.4503, 0.0000, 0.0000],\n",
      "          [0.7628, 0.9032, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.6324,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.1870, 0.0821, 0.5506,  ..., 0.2527, 0.0000, 0.0000],\n",
      "          [0.5588, 0.0000, 0.6477,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [1.6023, 0.0000, 0.2376,  ..., 0.0000, 0.3941, 0.4572],\n",
      "          ...,\n",
      "          [0.2920, 0.0000, 0.0000,  ..., 0.4008, 0.5666, 0.3007],\n",
      "          [0.0000, 0.0000, 0.3128,  ..., 0.0000, 1.0628, 0.1435],\n",
      "          [0.0000, 0.4643, 0.1186,  ..., 0.0000, 0.1424, 0.4645]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2722, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.7703,  ..., 0.7421, 0.9209, 0.0000],\n",
      "          [0.4617, 0.0000, 0.2965,  ..., 0.6497, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.7874, 0.0323, 0.0000,  ..., 0.0000, 0.5124, 0.5157],\n",
      "          [0.5180, 0.3915, 0.0647,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.6475, 0.0000,  ..., 0.2894, 0.1612, 0.0704]],\n",
      "\n",
      "         [[0.0297, 1.1681, 0.0000,  ..., 0.0000, 0.0000, 1.4502],\n",
      "          [0.0000, 0.0000, 0.3155,  ..., 0.0706, 0.3985, 0.0102],\n",
      "          [0.0704, 0.3253, 0.2809,  ..., 1.2180, 0.2656, 0.0000],\n",
      "          ...,\n",
      "          [0.3249, 0.4044, 0.9485,  ..., 0.0000, 0.3851, 0.0000],\n",
      "          [0.0000, 1.3052, 0.0000,  ..., 0.0000, 0.0608, 0.1690],\n",
      "          [0.0000, 0.7380, 0.4501,  ..., 1.0500, 0.0000, 0.2613]],\n",
      "\n",
      "         [[0.3988, 0.0000, 0.1976,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2982, 0.5017,  ..., 0.3185, 0.1182, 1.0372],\n",
      "          [0.3696, 0.4950, 0.0000,  ..., 0.0000, 0.0000, 0.0515],\n",
      "          ...,\n",
      "          [0.1496, 0.0000, 0.0868,  ..., 0.5631, 1.2815, 0.0000],\n",
      "          [0.0000, 0.4969, 0.0000,  ..., 0.2428, 0.4789, 0.1489],\n",
      "          [0.0496, 0.0000, 0.9789,  ..., 0.0000, 0.1363, 0.4365]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.2999, 0.2151,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0156, 0.0000,  ..., 0.0000, 1.0236, 0.3804],\n",
      "          [0.7791, 0.6128, 0.1689,  ..., 1.0409, 0.0000, 0.7349],\n",
      "          ...,\n",
      "          [0.9605, 0.0000, 0.5839,  ..., 0.0000, 0.4660, 0.0000],\n",
      "          [0.0000, 0.0000, 0.8577,  ..., 0.0000, 0.0760, 0.3114],\n",
      "          [0.0000, 0.4243, 0.3822,  ..., 0.0000, 0.6456, 0.0000]],\n",
      "\n",
      "         [[0.5264, 0.0368, 0.0000,  ..., 1.1512, 0.0000, 0.0000],\n",
      "          [0.3665, 0.0000, 0.3101,  ..., 0.1921, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.6346],\n",
      "          ...,\n",
      "          [0.0250, 0.3682, 0.2000,  ..., 0.9726, 0.9667, 0.0000],\n",
      "          [0.0000, 1.2055, 0.0000,  ..., 0.0713, 0.0000, 0.0094],\n",
      "          [0.0000, 1.2463, 0.0000,  ..., 0.7584, 1.1807, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 1.0038,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2988, 0.0000, 0.1300,  ..., 0.0000, 0.2847, 0.4536],\n",
      "          [0.0000, 0.4158, 0.0000,  ..., 0.0710, 0.2153, 0.0000],\n",
      "          ...,\n",
      "          [0.1968, 0.0532, 0.2385,  ..., 0.0000, 0.5520, 0.0000],\n",
      "          [0.7906, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.7152],\n",
      "          [0.0000, 0.7447, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.6086, 0.3773, 0.7110,  ..., 0.5916, 0.8403, 0.0000],\n",
      "          [0.0797, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.7028],\n",
      "          [0.6209, 0.0365, 0.0000,  ..., 1.1797, 0.0315, 0.5037],\n",
      "          ...,\n",
      "          [0.5188, 0.3287, 0.0000,  ..., 0.0000, 0.0000, 0.0112],\n",
      "          [0.5057, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1554],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.8958]],\n",
      "\n",
      "         [[0.0000, 0.1398, 0.4872,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2689, 0.4261, 0.0000,  ..., 0.0645, 0.1473, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0134, 0.0000, 0.9648],\n",
      "          ...,\n",
      "          [0.1001, 0.0000, 0.7695,  ..., 0.0000, 0.6647, 0.0000],\n",
      "          [0.0000, 0.1107, 0.0000,  ..., 0.0000, 0.0000, 0.6340],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1354, 0.7125, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.6281,  ..., 0.0000, 0.5073, 0.0000],\n",
      "          [0.0000, 0.5527, 0.5145,  ..., 0.0000, 0.5257, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1517, 0.0000, 0.2647],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.5356, 0.5810, 0.4790],\n",
      "          [0.0000, 0.4047, 0.0221,  ..., 0.0910, 0.0000, 0.0000],\n",
      "          [0.0000, 0.2876, 0.1203,  ..., 0.0000, 0.5455, 0.0000]]]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class ModuleDict(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModuleDict, self).__init__()\n",
    "        self.choices = nn.ModuleDict({\n",
    "            'conv': nn.Conv2d(10, 10, 3),\n",
    "            'pool': nn.MaxPool2d(3)\n",
    "        })\n",
    "\n",
    "        self.activations = nn.ModuleDict({\n",
    "            'relu': nn.ReLU(),\n",
    "            'prelu': nn.PReLU()\n",
    "        })\n",
    "\n",
    "    def forward(self, x, choice, act):\n",
    "        x = self.choices[choice](x)\n",
    "        x = self.activations[act](x)\n",
    "        return x\n",
    "\n",
    "net = ModuleDict()\n",
    "\n",
    "fake_img = torch.randn((4, 10, 32, 32))\n",
    "\n",
    "output = net(fake_img, 'conv', 'relu')\n",
    "# output = net(fake_img, 'conv', 'prelu')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/team/zhaohongwei/anaconda3/envs/cl/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "net = models.resnet50()\n",
    "print(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
